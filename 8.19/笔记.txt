正则: import re

查找:
re.match(pattern,string,flag): 必须从第一位开始匹配

re.search(pattern,string,flag): 默认只匹配到第一个就结束

从字符串里面提取数据:

re.findall(pattern,string,flag)

findall和()的结合使用: 一般使用findall提取出()里面的内容

语法:

或者:
| : 具体值得写出来  a|b|c
[0-9a-zA-Z]
[^]: 非

量词: {}

{n}
{n,m}
{n,}

{,m}(错误)

? : 可有可无  {0,1}

* : 大于等于0 {0,}

+ : 大于等于1 {1,}

转义:
\d : 数字
\D : 非数字

\w : 数字字母下划线
\W : 非数字字母下划线

\s : 换行或者空格
\S : 非换行,空格

. : 匹配除了换行以外的任意字符

flag:
re.I : 忽略大小写

re.S : 让.也能匹配到换行

.+ : 贪婪模式

.+? : 匹配到第一个符号要求的内容就停止当前匹配


网页文件: .html

打开位置: 浏览器打开

标签: <>包裹起来的内容  一般是具有一些特殊意义的  本身是不做显示的

单标签: 开始标签 <单词> img(控制图片的显示)

双标签: 开始标签和结束标签 <单词>标签内容</单词>  (最常见,最多)

a标签: 负责网页的跳转

标签的格式:
<单词 属性名="属性值" 属性名="属性值">标签内容</单词>
多个属性中间空格隔开

属性: 描述标签的信息

网址: 网页地址,还可能是文件地址

格式: http:// 或者 https://开头

普通网址:

https://www.baidu.com/

文件地址: https://或者http://开头,文件后缀结尾
https://www.baidu.com/img/PCtm_d9c8750bed0b3c7d089fa7d55720d6cf.png

本地文件地址
4.jpg

标签的关系:
并列(兄弟)关系: 标签同时被包裹在同一个标签里面

嵌套(父子)关系: 一个标签被包裹在另外一个标签 (父标签,子标签)

1.从网页源代码中取数据,第一次进行代码的结构分析,制定好规则,先尝试一下能不能取到对应的数据;如果取出的数据不是我们想要的,那就往标签的上一层标签去写规则 (已经可以取出大部分数据,如果结构都一样,可以直接将所有的数据取出来)

2.如果第一个规则,取不出来所有的数据,先从网页中找出哪些数据没取出来;然后再去分析这些没取出来的数据的代码结构

3.数据持久化(将数据保存到本地csv文件里面)


另外一种方式解析数据 (规则还是一样的写法)
1.获取到每条数据的整体源代码
2.将规则作用在该代码里面(那么每次取出来的结果就是和每条数据息息相关的结果,不用再去管哪条数据丢失了哪些信息)


爬虫: 模拟浏览器访问网站,爬取网页上的信息,存储到本地

对于你们现在来说,如何来获取网页源代码才是最重要的

通过爬虫获取网页源代码

反爬虫: 禁止爬取网页内容

模拟浏览器: 请求头

爬虫的模块: import urllib.request

b'': 二进制数据

response.read(): 返回的是二进制数据

解码: 将二进制数据 --> 字符串

方式: 二进制数据.decode(编码方式)

编码方式: 默认为utf-8



